{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP3314 - Assignment 1 \n",
    "created by krohak 2018-02-15\n",
    "\n",
    "** This notebook contains the implementation of a k-nn classifier from scratch and some experiments with it. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first import some essential Python libraries we'll use throughout the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Preprocessing\n",
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data in a Pandas dataframe and have a quick look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wisc_data = pd.read_csv(\"wisc_bc_data.csv\")\n",
    "wisc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wisc_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get rid of the 'id' column of the data since it is unnecessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wisc_data = wisc_data.iloc[:,1:] # get rid of the id\n",
    "wisc_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also store the 'diagnosis' column in a separate dataframe since it corresponds to the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = wisc_data.iloc[:,0]\n",
    "wisc_data = wisc_data.iloc[:,1:] # get rid of the labels\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get a quick look at the graph of the raw dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wisc_data.plot()\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization:\n",
    "We will use two ways to normalize the data:\n",
    "1. Feature scaling: Making it range from 0-1 for all columns using the max() and min() value\n",
    "2. Standard score: Using mean() and std() to find out how many standard deviations above the mean a certain value lies\n",
    "\n",
    "Lets create functions for both types of normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_scalling(dataframe):\n",
    "    return (dataframe - dataframe.min(0))/ (dataframe.max(0) - dataframe.min(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standard_score(dataframe):\n",
    "    return (dataframe - dataframe.mean()) / dataframe.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the feature scaled normalized data which should be in the range 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wisc_normalized = feature_scalling(wisc_data)\n",
    "wisc_normalized.plot()\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the standard score normalized data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wisc_normalized = standard_score(wisc_data)\n",
    "wisc_normalized.plot()\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will normalize the data using feature scalling in our initial experiments, thus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wisc_normalized = feature_scalling(wisc_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting training and testing datasets:\n",
    "\n",
    "Initially, we split the data from 0-468 for training and the remaining 100 for testing.\n",
    "We can use `train_test_split()` from `sklearn.cross_validation` to split the testing and training data according to the percentage of the testing data like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# `test_size` is the fraction of the data used for testing. \n",
    "# Note that instead of passing the entire dataframe, we pass just the values for convenience\n",
    "X_train, X_test, y_train, y_test = train_test_split(wisc_normalized.values, labels.values, test_size = 0.175, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - KNN Classifier from scratch\n",
    "In this part, we create our KNeighboursClassifier class with the `fit()` and `predict()` functions (implementing the interface of scikitlearn's KNeighboursClassifier)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A brief overview of what the functions in `MyKNeighboursClassifier` do:\n",
    "\n",
    "`fit()`- \n",
    "\n",
    "`uniform_distances()` - \n",
    "\n",
    "`uniform()` -\n",
    "\n",
    "`predict()` - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyKNeighborsClassifier(object):\n",
    "\n",
    "    def __init__(self,k=5,weights='uniform'):\n",
    "        self.k=k\n",
    "        self.weights=weights\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def uniform(self, X_test):\n",
    "        distances = self.uniform_distances(self.X_train, X_test)\n",
    "        y_pred = []\n",
    "        \n",
    "        # for all indices of X_test\n",
    "        for i in range(X_test.shape[0]):\n",
    "            top_k = []\n",
    "\n",
    "            # for each k, take its label\n",
    "            for j in range(self.k):\n",
    "                top_k.append(distances[i][j][1])\n",
    "                \n",
    "            # count the number of labels of each type, take the most common label\n",
    "            pred = Counter(top_k).most_common(1)[0][0]\n",
    "            y_pred.append(pred)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    \n",
    "    def uniform_distances(self, X_train, X_test):\n",
    "        distances = []\n",
    "\n",
    "        # for each node in x_test\n",
    "        for i in range(X_test.shape[0]):\n",
    "            euclidian_dist = np.zeros(X_train.shape[0])\n",
    "            distance_i = []\n",
    "\n",
    "            # for each node in x_train\n",
    "            for j in range(X_train.shape[0]):\n",
    "\n",
    "                # compute the euclidian distance from i to j\n",
    "                euclidian_dist[j] = np.sqrt(np.sum(np.square(np.array(X_test[i]) - np.array(X_train[j]))))\n",
    "\n",
    "                # append in distance_i list along with the label of j\n",
    "                distance_i.append([euclidian_dist[j], self.y_train[j]])\n",
    "\n",
    "            # sort in decreasing order of distances\n",
    "            distance_i = sorted(distance_i)\n",
    "            distances.append(distance_i)\n",
    "\n",
    "        return distances\n",
    "\n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        return self.uniform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing its accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = MyKNeighborsClassifier(k=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neigh.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = neigh.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_pred , y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we created the weighted version of MyKNeighboursClassifier. We include two new functions:\n",
    "\n",
    "`weighted_distances()`- \n",
    "\n",
    "`distance()`-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys={'M':0,'B':1,0:'M',1:'B'} # for converting the labels into binary classifications and vice-versa\n",
    "\n",
    "class MyKNeighborsClassifier(object):\n",
    "\n",
    "    def __init__(self,k=5,weights='uniform'):\n",
    "        self.k=k\n",
    "        self.weights=weights\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def weighted(self, X_test):\n",
    "        distances = self.weighted_distances(self.X_train, X_test)\n",
    "        y_pred = []\n",
    "\n",
    "        # for all indices of X_test\n",
    "        for i in range(X_test.shape[0]):\n",
    "            top_k = []\n",
    "            k_dist = []\n",
    "\n",
    "            # for each k\n",
    "            for j in range(self.k):\n",
    "                top_k.append(distances[i][j][1])\n",
    "                \n",
    "                # we store the inverse distances for the denominator\n",
    "                k_dist.append(1/distances[i][j][0])\n",
    "                \n",
    "            # sum of k labels weighted acording to the inverse of their distances / sum of k inverse distances\n",
    "            sum_k = sum(top_k)/sum(k_dist)\n",
    "            \n",
    "            # round off to classify between 0 to 1 and convert back to M or B\n",
    "            y_pred.append(keys[sum_k.round()])\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "\n",
    "    def weighted_distances(self, X_train, X_test):\n",
    "        distances = []\n",
    "\n",
    "        # for each node in x_test\n",
    "        for i in range(X_test.shape[0]):\n",
    "            euclidian_dist_sq = np.zeros(X_train.shape[0])\n",
    "            distance_i = []\n",
    "\n",
    "            # for each node in x_train\n",
    "            for j in range(X_train.shape[0]):\n",
    "\n",
    "                # compute the square of the euclidian distance from i to j\n",
    "                euclidian_dist_sq[j] = np.sum(np.square(np.array(X_test[i]) - np.array(X_train[j])))\n",
    "\n",
    "                # calculate the label weight by converting j's label into binary classification\n",
    "                # and multiplying with inverse of the distance from i to j\n",
    "                label_weight = keys[self.y_train[j]]/euclidian_dist_sq[j]\n",
    "                \n",
    "                # append in distance_i list \n",
    "                distance_i.append([euclidian_dist_sq[j], label_weight])\n",
    "                \n",
    "            # sort in decreasing order of distances and append\n",
    "            distances.append(sorted(distance_i))\n",
    "\n",
    "        return distances\n",
    "  \n",
    "\n",
    "    def uniform(self, X_test):\n",
    "        distances = self.uniform_distances(self.X_train, X_test)\n",
    "        y_pred = []       \n",
    "        for i in range(X_test.shape[0]):\n",
    "            top_k = []\n",
    "            for j in range(self.k):\n",
    "                top_k.append(distances[i][j][1])\n",
    "            pred = Counter(top_k).most_common(1)[0][0]\n",
    "            y_pred.append(pred)\n",
    "        return y_pred\n",
    "    \n",
    "    def uniform_distances(self, X_train, X_test):\n",
    "        distances = []\n",
    "        for i in range(X_test.shape[0]):\n",
    "            euclidian_dist = np.zeros(X_train.shape[0])\n",
    "            distance_i = []\n",
    "            for j in range(X_train.shape[0]):\n",
    "                euclidian_dist[j] = np.sqrt(np.sum(np.square(np.array(X_test[i]) - np.array(X_train[j]))))\n",
    "                distance_i.append([euclidian_dist[j], self.y_train[j]])\n",
    "            distance_i = sorted(distance_i)\n",
    "            distances.append(distance_i)\n",
    "        return distances\n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        if self.weights == 'distance':\n",
    "            return self.weighted(X_test)\n",
    "        return self.uniform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing its accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = MyKNeighborsClassifier(k=21,weights='distance')\n",
    "neigh.fit(X_train,y_train)\n",
    "y_pred = neigh.predict(X_test)\n",
    "print(accuracy_score(y_pred , y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improvement!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(X_test.shape[0])], [keys[x] for x in y_test], \"co\")\n",
    "plt.plot([i for i in range(X_test.shape[0])], [keys[x] for x in y_pred] ,\"r+\")\n",
    "plt.axis([0,100,-1,+2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, axes = plt.subplots(1,2)\n",
    "\n",
    "colors1 = ['#c2c2f0','#ffcc99']\n",
    "colors2 = ['#66b3ff','#ffff55']\n",
    "\n",
    "labels = 'True_M', 'True_B'\n",
    "counts = Counter(y_test)\n",
    "sizes = [counts['M'], counts['B']]\n",
    "axes[0].pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors1, startangle=90)\n",
    "axes[0].axis('equal')\n",
    "\n",
    "labels = 'Pred_M', 'Pred_B'\n",
    "counts = Counter(y_pred)\n",
    "sizes = [counts['M'], counts['B']]\n",
    "axes[1].pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors2, startangle=90)\n",
    "axes[1].axis('equal')  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = 'True_M', 'True_B'\n",
    "counts1 = Counter(y_test)\n",
    "sizes1 = [counts1['M'], counts1['B']]\n",
    "\n",
    "\n",
    "labels2 = 'Pred_M', 'Pred_B'\n",
    "counts2 = Counter(y_pred)\n",
    "sizes2 = [counts2['M'], counts2['B']]\n",
    "\n",
    "colors1 = ['#c2c2f0','#ffcc99']\n",
    "colors2 = ['#66b3ff','#ffff55']\n",
    "\n",
    "explode = (0.2,0.2) \n",
    "\n",
    "plt.pie(sizes1, autopct='%1.1f%%', colors=colors1, pctdistance=0.85, startangle=90, frame=True)\n",
    "plt.pie(sizes2, autopct='%1.1f%%', colors=colors2, pctdistance=0.85, radius=0.75, startangle=90)\n",
    "centre_circle = plt.Circle((0,0),0.5,color='black', fc='white',linewidth=0)\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.legend(labels = labels1 + labels2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_fake = 0\n",
    "M_fake = 0\n",
    "\n",
    "for i,y in enumerate(y_test):\n",
    "    if y=='M' and y_pred[i]=='B':\n",
    "        B_fake+=1\n",
    "    elif y=='B' and y_pred[i]=='M':\n",
    "        M_fake+=1\n",
    "        \n",
    "B_real = counts2['B'] - B_fake\n",
    "M_real = counts2['M'] - M_fake\n",
    "print(B_real,B_fake,M_real,M_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = 'Pred_M', 'Pred_B'\n",
    "counts1 = Counter(y_test)\n",
    "sizes1 = [counts2['M'], counts2['B']]\n",
    "\n",
    "explode1 = (0,0)\n",
    "\n",
    "labels2 = 'True Positive', 'False Positive'\n",
    "counts2 = Counter(y_pred)\n",
    "sizes2 = [M_real,M_fake,B_real,B_fake]\n",
    "\n",
    "explode2 = (0,0,0,0)\n",
    "\n",
    "colors1 = ['#66b3ff','#ffff55']\n",
    "colors2 = ['#aaff77','#ff6666']\n",
    "\n",
    "plt.pie(sizes1, autopct='%1.1f%%', colors=colors1, explode=explode1, pctdistance=1.1, startangle=90, frame=True)\n",
    "plt.pie(sizes2, autopct='%1.1f%%', colors=colors2, explode=explode2, pctdistance=0.65, radius=0.75, startangle=90)\n",
    "centre_circle = plt.Circle((0,0),0.5,color='black', fc='white',linewidth=0)\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.legend(labels = labels1 + labels2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Experiments and Comparison\n",
    "### Sklearn KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=5,weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = neigh.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_pred , y_test)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
